---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Financial Econometrics 871 Practical Exam 2022: Question 5"
subtitle: "Question 5"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Tian Cater"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "University of Stellenbosch, Western Cape, South Africa^[2022-11-27]" # First Author's Affiliation
Email1: "19025831\\@sun.ac.za" # First Author's Email address

#Author2: "John Smith"
#Ref2: "Some other Institution, Cape Town, South Africa"
#Email2: "John\\@gmail.com"
#CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

#Author3: "John Doe"
#Email3: "Joe\\@gmail.com"

#CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
#keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
#JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)

pacman::p_load("MTS", "robustbase","fGarch", "kableExtra", "knitr")
pacman::p_load("tidyverse", "devtools", "rugarch", "rmgarch", 
    "forecast", "tbl2xts", "lubridate", "PerformanceAnalytics", 
    "ggthemes", "MTS", "fmxdat", "rmsfuns", "ggpubr", "broom", "rstatix", "modelr")


cncy <- read_rds("C:/Users/tianc/Rproj/FinMetrics871_Exam/19025831/data/currencies.rds")
cncy_Carry <- read_rds("C:/Users/tianc/Rproj/FinMetrics871_Exam/19025831/data/cncy_Carry.rds")
cncy_value <- read_rds("C:/Users/tianc/Rproj/FinMetrics871_Exam/19025831/data/cncy_value.rds")
cncyIV <- read_rds("C:/Users/tianc/Rproj/FinMetrics871_Exam/19025831/data/cncyIV.rds")
bbdxy <- read_rds("C:/Users/tianc/Rproj/FinMetrics871_Exam/19025831/data/bbdxy.rds")

Currency_names_full <- cncy |> summarise(Name) |> unique() |> pull() 

# Remove the common second part of names

Curr_df <- cncy |> mutate(Name = gsub( "_Cncy", "", Name)) |> mutate(Name = gsub( "_Inv", "", Name)) 



Countries_to_consider <- c("Brazil","EU","India","Poland","Zambia","Turkey","SouthAfrica","UK")

# filter countries to consider

Curr_df <- Curr_df |> filter(Name %in% Countries_to_consider) 

SD_plot_df <- Curr_df |>  arrange(date) |> 
    
    group_by(Name) |> 
    
    mutate(Growth = log(Price) - lag(log(Price))) |> 
    
    filter(date > dplyr::first(date)) |>  
    
    mutate(scaledgrowth = Growth - mean(Growth, rm.na = T)) |>     # Scale the Growth by demeaning
    
    mutate(SampleSD = (sqrt(scaledgrowth^2))) |> 
    
    ungroup() |> 
    
    filter(date > lubridate::ymd(20041231))

# Calculate the scaled (demeaned) log growth for BBDXY 

ln_bbdxy <- bbdxy |> arrange(date) |> 
    
    mutate(Growth = log(Price) - lag(log(Price))) |> 
    
    filter(date > dplyr::first(date)) |>  
    
    mutate(scaledgrowth = Growth - mean(Growth, rm.na = T)) |>     # Scale the Growth by demeaning
    
    mutate(SampleSD = (sqrt(scaledgrowth^2))) |> 
    
    ungroup() |> 
    
    filter(date > lubridate::ymd(20041231))

# Now I merge it with the rest, and remove the UK, EU, and Zambia

gwt <- SD_plot_df |> select(date, Name, Growth) |> filter(!(Name %in% c("EU", "UK", "Zambia"))) |> 
    
    pivot_wider(names_from = "Name", values_from = "Growth") |> 

    left_join(ln_bbdxy |> select(date, Growth) |> rename(BBDXY = Growth), by= c("date")) |> 
    
    pivot_longer(cols = -date, values_to = "Growth", names_to = "Currency") |> 
    
    mutate(Growth = coalesce(Growth, 0)) 


# Change to xts format

gwt_xts <- gwt |> 
    
    tbl_xts(cols_to_xts = Growth, spread_by = Currency)

# As in the tut, I select a VAR order of zero for the mean equation, and simply use the mean of each series.
# The mean equation is thus in our case simply: Growth = mean(Growth) + et

# Then, for every series, a standard univariate GARCH(1,1) is run - giving us:
# et and sigmat, which is then used to calculate the standardized resids, zt, which is used in DCC calcs after.

DCCPre <- dccPre(gwt_xts, include.mean = F, p=0) # Find a nice way to put this in a table

Vol <- DCCPre$marVol

colnames(Vol) <- colnames(gwt_xts)

Vol <- 
  data.frame( cbind( date = index(gwt_xts), Vol)) |>  # Add date column which dropped away...
  mutate(date = as.Date(date)) |>  tibble::as_tibble()  # make date column a date column...



TidyVol <- Vol |>  pivot_longer(names_to = "Stocks", values_to =  "Sigma", cols =  -date)

# The standardized residuals

StdRes <- DCCPre$sresi

# I first do the detach trick from the tut:

detach("package:tidyverse", unload=TRUE)
detach("package:fmxdat", unload=TRUE)
detach("package:rmsfuns", unload=TRUE)
detach("package:tbl2xts", unload=TRUE)
detach("package:ggpubr", unload=TRUE)
detach("package:rstatix", unload=TRUE)
detach("package:modelr", unload=TRUE)
detach("package:broom", unload=TRUE)
detach("package:tidyr", unload=TRUE)
detach("package:dplyr", unload=TRUE)

DCC <- dccFit(StdRes,type = "Engle") 

pacman::p_load(tidyverse,fmxdat, rmsfuns, tbl2xts, tidyr, ggpubr, broom,rstatix, modelr )

Rhot <- DCC$rho.t
# Right, so it gives us all the columns together in the form:
# X1,X1 ; X1,X2 ; X1,X3 ; ....

# So, let's be clever about defining more informative col names. 
# I will create a renaming function below:
ReturnSeries = gwt_xts
DCC.TV.Cor = Rhot

renamingdcc <- function(ReturnSeries, DCC.TV.Cor) {
  
ncolrtn <- ncol(ReturnSeries)
namesrtn <- colnames(ReturnSeries)
paste(namesrtn, collapse = "_")

nam <- c()
xx <- mapply(rep, times = ncolrtn:1, x = namesrtn)
# Now let's be creative in designing a nested for loop to save the names corresponding to the columns of interest.. 

# TIP: draw what you want to achieve on a paper first. Then apply code.

# See if you can do this on your own first.. Then check vs my solution:

nam <- c()
for (j in 1:(ncolrtn)) {
for (i in 1:(ncolrtn)) {
  nam[(i + (j-1)*(ncolrtn))] <- paste(xx[[j]][1], xx[[i]][1], sep="_")
}
}

colnames(DCC.TV.Cor) <- nam

# So to plot all the time-varying correlations wrt SBK:
 # First append the date column that has (again) been removed...
DCC.TV.Cor <- 
    data.frame( cbind( date = index(ReturnSeries), DCC.TV.Cor)) %>% # Add date column which dropped away...
    mutate(date = as.Date(date)) %>%  tbl_df() 

DCC.TV.Cor <- DCC.TV.Cor %>% gather(Pairs, Rho, -date)

DCC.TV.Cor

}

# Let's see if our function works! Excitement!
Rhot <- 
  renamingdcc(ReturnSeries = gwt_xts, DCC.TV.Cor = Rhot)


```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

The purpose of this question is to comment on the following two statements:
\begin{enumerate}
  \item The South African rand (ZAR) has, over the past few years, been one of the most volatile currencies
  \item The ZAR has generally performed well during periods where G10 currency carry trades have been favourable, and these currency valuations are relatively cheap. Globally, it has been one of the currencies that most benefit during periods when the Dollar is comparatively strong, indicating a risk-on sentiment.
\end{enumerate}

In summary, the findings here are in contrast to the first statement. That is, even though the ZAR has been highly volatile in the past few years, it is not one of the most volatile, having similar variance in the recent years as in the more distant past. With respect to the second statement, the evidence here strongly agrees. That is, that the ZAR is partially insulated from periods of weak performance in the G10 countries. Specifically, during periods where the USD has been weak, the ZARs positive dynamic conditional correlation with the USD has dropped significantly.

# Comparing Global Currency Volatiliy to the ZAR

To investigate the first statement, I select 8 countries' currencies: Brazil, EU, India, SA, Turkey, Poland, Zambia, and the UK and compare their respective dollar exchange rates. The reasoning behind the selection is diversity in comparison; by including developing nations with historically low levels of spillovers from the US (Brazil and India), one of the largest economies in Africa (Zambia), two developing nations from Asia (Poland and Turkey), and two of the strongest currencies in the world (UK and EU), a clear picture can be painted on how volatile the ZAR is in comparison. Figure \ref{Figure1} graphs the scaled logarithmic growth of the respective currencies to the USD since 2005, giving weak hints that the ZAR may not have been more volatile in the last couple of years than the first comment suggests. 

```{r Scaled Growth Plot,  warning =  FALSE, fig.align = 'center', fig.cap = "Scaled (demeaned) Log Growth of Respective Currencies to USD since 2005. \\label{Figure1}", fig.ext = 'png', fig.height = 4.5, fig.width = 6}

Scaledgrowth_plot_df <-  SD_plot_df |> 
 
    ggplot() + 
  
  geom_line(aes(date, scaledgrowth , color = Name), size = 0.6, alpha = 0.7) +
    
    facet_wrap(~Name, scales = "free_y")+
  
   fmxdat::theme_fmx(title.size = fmxdat::ggpts(30), 
                    subtitle.size = fmxdat::ggpts(0),
                    caption.size = fmxdat::ggpts(25),
                    CustomCaption = T) + 
    
  fmxdat::fmx_cols() + 
  
  labs(x = "", y = "%", caption = "Note:\nCalculation own",
       title = "Scaled (demeaned) Log Growth of Respective Currencies to USD since 2005.",
       subtitle = "")

# Finplot for finishing touches:

fmxdat::finplot(Scaledgrowth_plot_df, x.vert = T, x.date.type = "%Y", x.date.dist = "3 years", darkcol = T, legend_pos = "right")

```

To get an initial comparison of the volatility of the selected currencies, Figure \ref{Figure2} plots the respective sample standard deviation in scaled log growth against the dollar.^[The dates are filtered to consider the period from 2006 onwards to remove extremely volatile periods for international currencies.] Upon this initial inspection of Figure \ref{Figure2}, it is apparent that the ZAR has recently not been the most volatile against the USD.  

```{r Sample SD Plot,  warning =  FALSE, fig.align = 'center', fig.cap = "Sample Standard Deviation of Respective Currencies to USD since 2005. \\label{Figure2}", fig.ext = 'png', fig.height = 4.5, fig.width = 6}

SD_plot <- SD_plot_df |>  

  ggplot() + 
  
   geom_line(aes(date, SampleSD , color = Name), size = 0.6, alpha = 0.7) +
    
    facet_wrap(~Name, scales = "free_y")+
  
   fmxdat::theme_fmx(title.size = fmxdat::ggpts(30), 
                    subtitle.size = fmxdat::ggpts(0),
                    caption.size = fmxdat::ggpts(25),
                    CustomCaption = T) + 
    
  fmxdat::fmx_cols() + 
  
  labs(x = "", y = "%", caption = "Note:\nCalculation own",
       title = "Sample Standard Deviation of Respective Currencies to USD since 2005.",
       subtitle = "")

# Finplot for finishing touches:

fmxdat::finplot(SD_plot, x.vert = T, x.date.type = "%Y", x.date.dist = "3 years", darkcol = T, legend_pos = "right")

```

# DCC Multivariate GARCH Model

To better understand the volatility of these currencies, I take a deeper dive into the volatility of these currencies and fit a multivariate GARCH model, but by also including the Bloomberg Dollar Spot Index (BBDXY) as a variable; it tracks the performance of a basket of 10 leading global currencies versus the U.S. Dollar. It has a dynamically updated composition and represents a diverse set of important currencies from trade and liquidity perspectives.

I start by conducting the MARCH test, which indicates that all the multivariate portmanteau tests reject the null of no conditional heteroskedasticity, motivating my use of a MVGARCH model.^[The relevant test statistics can be seen in my README.]

I decide to use a DCC MVGARCH Model since DCC models offer a simple and more parsimonious means of doing MV-vol modelling. In particular, it relaxes the constraint of a fixed correlation structure (assumed by the CCC model), to allow for estimates of time-varying correlation. 

The DCC GARCH estimated volatility (sigma) for each currency is depicted in Figure \ref{Figure3}. These volatility estimates are slightly different than the simple sample SD graphed in Figure \ref{Figure2} above, in that the ZARs volatility has increased relative to the other currencies, however, Brazil and Turkey still showcases more volatility, even in the recent few years.

```{r TidyVol_plot,  warning =  FALSE, fig.align = 'center', fig.cap = "DCC GARCH: Estimated Volatility (Sigma) for Each Currency \\label{Figure3}", fig.ext = 'png', fig.height = 4, fig.width = 6}


TidyVol_plot <- TidyVol |> ggplot() + 
  
  geom_line(aes(date, Sigma , color = Stocks), size = 0.9, alpha = 0.6) +
    
  
   fmxdat::theme_fmx(title.size = fmxdat::ggpts(30), 
                    subtitle.size = fmxdat::ggpts(0),
                    caption.size = fmxdat::ggpts(25),
                    CustomCaption = T) + 
    
  fmxdat::fmx_cols() + 
  
  labs(x = "", y = "Sigma", caption = "Note:\nCalculation own",
       title = "DCC GARCH: Estimated Volatility (Sigma) for Each Currency",
       subtitle = "Notice this includes the Bloomberg Dollar Spot Index (BBDXY)")
    
# And finally touches with finplot    

fmxdat::finplot(TidyVol_plot, x.vert = T, x.date.type = "%Y", x.date.dist = "2 years", darkcol = F, legend_pos = "right")

```

After fitting the DCC GARCH, I plot the dynamic conditional correlation with respect to the ZAR in Figure \ref{Figure4} below, where, even though the graph is not very clear, it is apparent that the ZAR is the least correlated with the Indian Rupee. To get a clearer picture of the impact of the USD on the ZAR, I remove some clutter and only plot the dynamic conditional correlations between the ZAR and the USD in Figure \ref{Figure5}. 

```{r Cond_corr_plot,  warning =  FALSE, fig.align = 'center', fig.cap = "Dynamic Conditional Correlations: South Africa (ZAR) \\label{Figure4}", fig.ext = 'png', fig.height = 3, fig.width = 6}

# Let's now create a plot for all the stocks relative to the other stocks...
g1 <- 
  ggplot(Rhot |>  filter(grepl("SouthAfrica_", Pairs ), !grepl("_SouthAfrica", Pairs)) ) + 
  geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
  theme_hc() +
  ggtitle("Dynamic Conditional Correlations: South Africa (ZAR)")

g1

```

In analysing Figure \ref{Figure5}, it becomes clear that The ZAR has generally performed well during periods where G10 currency carry trades have been favourable, and these currency valuations are relatively cheap. That is, in periods where the USD has performed poorly against the other G10 currencies (reflected by BBDXY), for example following the GFC from 2008 to 2012 and the COVID-19 pandemic from 2019 onwards, the ZAR has had the lowest conditional correlation with the BBDXY. Therefore, indicating that the ZAR is partially insulated against the backdrop of advanced economies' currency downturns, which indicates a risk-on sentiment


```{r Cond_corr_plot 2,  warning =  FALSE, fig.align = 'center', fig.cap = "Dynamic Conditional Correlation: South Africa (ZAR) and BBDXY \\label{Figure5}", fig.ext = 'png', fig.height = 3, fig.width = 6}
g2 <- 
  ggplot(Rhot |>  filter(Pairs %in% c("SouthAfrica_BBDXY"))) + 
  geom_line(aes(x = date, y = Rho, colour = Pairs)) + 
  theme_hc() +
  ggtitle("Dynamic Conditional Correlation: South Africa (ZAR) and BBDXY")

g2

```



<!-- Make title of bibliography here: -->
<!-- \newpage -->

\newpage

# References {-}

<div id="refs"></div>


